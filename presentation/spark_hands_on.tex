\documentclass[slidetop,9pt,utf8]{beamer}

\usepackage{CJKutf8}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{ifpdf}
\usepackage{textcomp}
\usepackage{color}
\usepackage{xcolor}
\usepackage{amsmath}
\usepackage{graphics}
\usepackage{array}
\usepackage{graphicx}
\usepackage{colortbl}
\usepackage{pinyin}
\usepackage{algorithm,algorithmic}
\usepackage{hyperref}
\usepackage{listingsutf8}
\usepackage{caption}
\usepackage{xspace}

\usetheme{JuanLesPins}
\useoutertheme{infolines}
%\usecolortheme{default}
%\usetheme{Boadilla}
\setbeamerfont{structure}{size*={11}{11}}

\DeclareCaptionFont{white}{\color{white}}
\DeclareCaptionFormat{listing}{\colorbox[cmyk]{0.43, 0.35, 0.35,0.01}{\parbox{\textwidth}{\hspace{15pt}#1#2#3}}}
\captionsetup[lstlisting]{format=listing,labelfont=white,textfont=white, singlelinecheck=false, margin=0pt, font={bf,footnotesize}}

\lstset{
   basicstyle=\footnotesize\ttfamily,
   numberstyle=\tiny,          
   numbersep=5pt,              
   tabsize=2,                  
   extendedchars=true,         
   breaklines=true,            
   keywordstyle=\color{red},
   showspaces=false,           
   showtabs=false,             
   xleftmargin=17pt,
   xrightmargin=17pt,
   framexleftmargin=5pt,
   framexrightmargin=5pt,
   framexbottommargin=4pt,
   showstringspaces=false,
   inputencoding=utf8/latin1      
 }

\lstdefinestyle{terminal}
{
  backgroundcolor=\color{black},
  basicstyle=\scriptsize\color{white}\ttfamily
}

\lstdefinestyle{code}
{
  frame=b,
  numbers=left,
  morecomment=[is]{/\*}{\*/}
}

% "define" Scala
\lstdefinelanguage{scala}{
  morekeywords={abstract,case,catch,class,def,%
    do,else,extends,false,final,finally,%
    for,if,implicit,import,match,mixin,%
    new,null,object,override,package,%
    private,protected,requires,return,sealed,%
    super,this,throw,trait,true,try,%
    type,val,var,while,with,yield},
  otherkeywords={=>,<-,<\%,<:,>:,\#,@},
  sensitive=true,
  morecomment=[l]{//},
  morecomment=[n]{/*}{*/},
  morestring=[b]",
  morestring=[b]',
  morestring=[b]"""
}

\begin{document}
\begin{CJK}{UTF8}{gbsn}

%--- Page de titre ---
\title{Spark Hands On}
%\subtitle{Creation of a multi-features Named Entity Disambiguation System}
\author{Olivier GIRARDOT, Vincent DOBA}
\institute{Paris Scala User Group}
\date{May 13, 2015}

\frame{\titlepage}

%--- Sommaire ---
\begin{frame}
  \frametitle{Content}
  \tableofcontents[hideallsubsections]
\end{frame}

\AtBeginSection{\frame{\sectionpage}}

\section{Prerequisite}

%--- Prerequisite for the machine ---
\begin{frame}
  \frametitle{Machine Prerequisite}

  \begin{block}{You should have a machine with}
    \begin{itemize}
      \item JDK 6+ (this hands on was developed using Oracle JDK 8) with Scala 2.10+
      \item SBT 13+
      \item Git
      \item An IDE with SBT/Scala support (for instance IDEA IntelliJ with SBT and Scala plugins)
      \item Downloaded Spark 1.3.1 prebuilt for Hadoop 2.6 from \href{http://www.apache.org/dyn/closer.cgi/spark/spark-1.3.1/spark-1.3.1-bin-hadoop2.6.tgz}{official Apache Spark site}
    \end{itemize}
  \end{block}

  \begin{block}{You should}
    \begin{itemize}
      \item Know Scala basis
      \item Be at ease with Scala's iterables transformations (map, flatmap, fold)
      \item Be at ease with higher order functions
    \end{itemize}
  \end{block}

\end{frame}

\begin{frame}[fragile]
  \frametitle{First Spark Run}

  \begin{block}{Perform following commands}
    \begin{lstlisting}[language=bash, style=terminal]
git clone https://github.com/vincentdoba/spark-hands-on.git
cd spark-hands-on
sbt "run-main psug.hands.on.prerequisite.WordCount README.md" 
    \end{lstlisting}
  \end{block}

  \begin{block}{You should obtain}
    \begin{lstlisting}[language=bash, style=terminal]
[info] Running psug.hands.on.prerequisite.WordCount README.md
[error] 15/05/08 17:37:36 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[info] (,48)
[info] (*,24)
[info] (####,16)
[info] (of,14)
[info] (the,11)
[info] (###,10)
[info] (Exercise,8)
[info] (Description,8)
[info] (Notions,8)
[info] (a,8)
[success] Total time: 25 s, completed 8 mai 2015 17:37:39
    \end{lstlisting}
  \end{block}

\end{frame}

\begin{frame}[fragile]
  \frametitle{Words Count Script}

  \lstinputlisting[language=scala, style=code, label=WordCount,caption=/src/main/scala/psug/hands/on/prerequisite/WordCount.scala]{../src/main/scala/psug/hands/on/prerequisite/WordCount.scala}

\end{frame}

\begin{frame}
  \frametitle{Important Notions}

  \begin{block}{Vocabulary}
    \begin{itemize}
      \item \textbf{Spark Conf} Configuration of the Spark Context, here contains application name and master to call
      \item \textbf{Spark Context} Main entry point, represents the connection to a Spark Cluster, used to create RDDs/Load file
      \item \textbf{Resilient Distribued Dataset} Spark Dataset on which we can apply actions and transformations
      \item \textbf{Transformations} functions that transform RDD to another RDD
      \item \textbf{Actions} functions that transform an RDD to output data
    \end{itemize}
  \end{block}

\end{frame}

\begin{frame}
  \frametitle{Important Notions}

  \begin{block}{Spark Scripting How To}
    \begin{itemize}
      \item Initiate a Spark Context
      \item Load a dataset and transform it to RDD thanks to the Spark Context
      \item Register Transformations on RDD
      \item Apply an Action to transformed RDD
      \item Do whatever you want with data obtained after 
      \item Stop Spark Context
    \end{itemize}
  \end{block}

\end{frame}

\begin{frame}
  \frametitle{SBT Configuration}

  \lstinputlisting[language=scala, style=code, label=WordCount,caption=/build.sbt]{../build.sbt}

\end{frame}

\section{Exercise 1 : Spark basis (SparkContext, RDD, Transformation, Action)}

\begin{frame}
  \frametitle{Presentation of Exercise}

  \begin{block}{Statement}
    We have three lists : first list contains the integers from 1 to 75, second list contains the integers from 25 to 100, and the third list contains primes under 100. We want to obtain the sum of square of integers that are under 100 and are not prime.
  \end{block}

  \begin{block}{What you will learn}
    \begin{itemize}
      \item Initialization of Spark Context
      \item Transform Scala lists to Spark RDDs
      \item Discover some transformations on RDDs
      \item Discover first action : sum
    \end{itemize}
  \end{block}

\end{frame}

\begin{frame}
  \frametitle{Exercise Code}

  \lstinputlisting[language=scala, style=code, label=Exercise1,caption=/src/main/scala/psug/hands/on/exercise01/SumOfSquareOfNonPrimeNumbers.scala]{../src/main/scala/psug/hands/on/exercise01/SumOfSquareOfNonPrimeNumbers.scala}

\end{frame}

\begin{frame}[fragile]
  \frametitle{New Notions (1)}

  \begin{lstlisting}[label=InitSparkContext, caption=Init Spark Context, language=scala, style=code]
val conf = new SparkConf()
  .setMaster("local")
  .setAppName("applicationName")
val sparkContext = new SparkContext(conf)
  \end{lstlisting}

  \begin{lstlisting}[label=ListToRdd, caption=Load List as RDD, language=scala, style=code]
val rdd:RDD[Int] = sparkContext.makeRDD(scalaList)
  \end{lstlisting}

\end{frame}

\begin{frame}[fragile]
  \frametitle{New Notions (2)}

  \begin{lstlisting}[label=RDDTransformation, caption=Apply transformation to RDD, language=scala, style=code]
val newRdd:RDD[Int] = oldRdd.map(x => x)
  \end{lstlisting}

  \begin{lstlisting}[label=RDDAction, caption=Apply action to RDD, language=scala, style=code]
val result:Int = rdd.sum()
  \end{lstlisting}

  \begin{lstlisting}[label=StopSparkContext, caption=Stop Spark Context, language=scala, style=code]
sparkContext.stop()
  \end{lstlisting}

\end{frame}

\begin{frame}

  \frametitle{New Transformations and Actions}

  \begin{block}{Transformations}
    \begin{center}
      \begin{tabular}{|m{2.1cm}|m{3.5cm}|m{5cm}|}
        \hline 
        \rowcolor{gray} \textbf{Transformation} & \textbf{Usage} & \textbf{Description} \\ \hline
        \textbf{union} & \textit{rdd1.union(rdd2)} & merge the two rdds \\ \hline
        \textbf{distinct} & \textit{rdd1.distinct()} & remove duplicates from rdd \\ \hline
        \textbf{subtract} & \textit{rdd1.substract(rdd2)} & remove values from rdd2 of rdd1 \\ \hline
        \textbf{map} & \textit{rdd1.map(f: (T) =\textgreater\xspace U)} & apply function f to elements of rdd1 \\ \hline
      \end{tabular}
    \end{center}
  \end{block}

  \begin{block}{Actions}
    \begin{center}
      \begin{tabular}{|m{2.1cm}|m{3.5cm}|m{5cm}|}
        \hline 
        \rowcolor{gray} \textbf{Action} & \textbf{Usage} & \textbf{Description} \\ \hline
        \textbf{sum} & \textit{rdd1.sum()} & sum the elements of RDD \\ \hline
      \end{tabular}
    \end{center}
  \end{block}

\end{frame}

\begin{frame}[fragile]
  \frametitle{Command and Result}

  \begin{block}{Command}
    \begin{lstlisting}[language=bash, style=terminal]
sbt "run-main psug.hands.on.exercise01.SumOfSquaresOfNonPrimeNumbers"
    \end{lstlisting}
  \end{block}

  \begin{block}{Result}
    \begin{lstlisting}[language=bash, style=terminal]
[info] The sum of square of numbers that are not prime and are under 100 is 272554.0
[success] Total time: 9 s, completed 8 mai 2015 21:23:22
    \end{lstlisting}
  \end{block}

\end{frame}

\section{Exercise 2 : Key/Values RDD, File Loading}

\begin{frame}
  \frametitle{Presentation of Exercise}

  \begin{block}{Statement}
    We have a text file containing the list of French departments. Which are the departments whose name contains Seine ? And Loire ? And Garonne ? And Rh√¥ne ?
  \end{block}

  \begin{block}{What you will learn}
    \begin{itemize}
      \item Load a file using a Spark Context
      \item New Actions and Transformations
      \item How to transform an RDD to a Key/Value RDD
    \end{itemize}
  \end{block}

\end{frame}

\begin{frame}
  \frametitle{Exercise Code}

  \lstinputlisting[language=scala, style=code, label=Exercise2,caption=/src/main/scala/psug/hands/on/exercise02/DepartmentsByRiver.scala]{../src/main/scala/psug/hands/on/exercise02/DepartmentsByRiver.scala}

\end{frame}

\begin{frame}[fragile]
  \frametitle{departements.txt File}

  \begin{verbatim}
Ain,01
Aisne,02
Allier,03
Alpes-de-Haute-Provence,04
Hautes-Alpes,05
Alpes-Maritimes,06
Ard√®che,07
Ardennes,08
Ari√®ge,09
Aube,10
Aude,11
Aveyron,12
Bouches-du-Rh√¥ne,13
Calvados,14
Cantal,15
Charente,16
Charente-Maritime,17
...
  \end{verbatim}

\end{frame}

\begin{frame}[fragile]
  \frametitle{New Notions}

  \begin{lstlisting}[label=LoadTextFile, caption=Load Text File, language=scala, style=code]
val rdd:RDD[String] = sparkContext.textFile("filePath")
  \end{lstlisting}

  \begin{lstlisting}[label=TransformToKeyValue, caption=Transform RDD to a Key/Value RDD, language=scala, style=code]
val keyValueRdd1:RDD[(K,V)] = oldRdd[T].map(f: (T) => (K,V))
val keyValueRdd2:RDD[(K,V)] = oldRdd[T]
  .flatMap(f: (T) => TraversableOnce[(K,V)])
  \end{lstlisting}

\end{frame}

\begin{frame}

  \frametitle{New Transformations and Actions}

  \begin{block}{Transformations}
    \begin{center}
      \begin{tabular}{|m{2.1cm}|m{3.5cm}|m{5cm}|}
        \hline 
        \rowcolor{gray} \textbf{Transformation} & \textbf{Usage} & \textbf{Description} \\ \hline
        \textbf{filter} & \textit{rdd1.filter(f: (T) =\textgreater\xspace boolean)} & filter by function f \\ \hline
        \textbf{flatMap} & \textit{rdd1.flatMap(f: (T) =\textgreater\xspace TraversableOnce[U])} & apply function f and flatten \\ \hline
        \textbf{groupByKey} & \textit{rdd1[(K,V)].groupByKey()} & create an RDD containing tuples (K, Seq(V)) \\ \hline
        \textbf{sortByKey} & \textit{rdd1[(K,V)].sortByKey()} & sort rdd1 by key \\ \hline
      \end{tabular}
    \end{center}
  \end{block}

  \begin{block}{Actions}
    \begin{center}
      \begin{tabular}{|m{2.1cm}|m{3.5cm}|m{5cm}|}
        \hline 
        \rowcolor{gray} \textbf{Action} & \textbf{Usage} & \textbf{Description} \\ \hline
        \textbf{collect} & \textit{rdd1.collect()} & retrieve all elements of RDD as Array \\ \hline
      \end{tabular}
    \end{center}
  \end{block}

\end{frame}

\begin{frame}[fragile]
  \frametitle{Command and Result}

  \begin{block}{Command}
    \begin{lstlisting}[language=bash, style=terminal]
sbt "run-main psug.hands.on.exercise02.DepartmentsByRiver"
    \end{lstlisting}
  \end{block}

  \begin{block}{Result}
    \begin{lstlisting}[language=bash, style=terminal]
[info] Les departements dont le nom contient Garonne sont Haute-Garonne, Lot-et-Garonne, Tarn-et-Garonne
[info] Les departements dont le nom contient Loire sont Indre-et-Loire, Loire, Haute-Loire, Loire-Atlantique, Loiret, Maine-et-Loire, Saone-et-Loire
[info] Les departements dont le nom contient Rhone sont Bouches-du-Rhone, Rhone
[info] Les departements dont le nom contient Seine sont Seine-Maritime, Seine-et-Marne, Hauts-de-Seine, Seine-Saint-Denis
[success] Total time: 8 s, completed 8 mai 2015 22:03:26
    \end{lstlisting}
  \end{block}

\end{frame}

\section{Exercise 3 : Spark SQL Context, JSON Loading, DataFrames}

\begin{frame}
  \frametitle{Presentation of Exercise}

  \begin{block}{Statement}
    We have a JSON file containing the list of French cities with population. What is the total population of France ?
  \end{block}

  \begin{block}{What you will learn}
    \begin{itemize}
      \item Initialize Spark SQL Context
      \item Load DataFrames from JSON File with a Spark SQL Context
      \item First Actions and Transformations on DataFrames
    \end{itemize}
  \end{block}

\end{frame}

\begin{frame}
  \frametitle{Exercise Code}

  \lstinputlisting[language=scala, style=code, label=Exercise3,caption=/src/main/scala/psug/hands/on/exercise03/TotalPopulation.scala]{../src/main/scala/psug/hands/on/exercise03/TotalPopulation.scala}

\end{frame}

\begin{frame}[fragile]
  \frametitle{demographie\_par\_commune.json File}

  \begin{verbatim}
{"CodeInsee":"01001",[...],"Population":784,[...]}
{"CodeInsee":"01002",[...],"Population":221,[...]}
{"CodeInsee":"01004",[...],"Population":13835,[...]}
{"CodeInsee":"01005",[...],"Population":1616,[...]}
{"CodeInsee":"01006",[...],"Population":116,[...]}
{"CodeInsee":"01007",[...],"Population":2362,[...]}
{"CodeInsee":"01008",[...],"Population":729,[...]}
{"CodeInsee":"01009",[...],"Population":340,[...]}
{"CodeInsee":"01010",[...],"Population":994,[...]}
{"CodeInsee":"01011",[...],"Population":363,[...]}
{"CodeInsee":"01012",[...],"Population":302,[...]}
{"CodeInsee":"01013",[...],"Population":163,[...]}
{"CodeInsee":"01014",[...],"Population":3476,[...]}
{"CodeInsee":"01015",[...],"Population":480,[...]}
{"CodeInsee":"01016",[...],"Population":399,[...]}
{"CodeInsee":"01017",[...],"Population":421,[...]}
{"CodeInsee":"01019",[...],"Population":20,[...]}
...
  \end{verbatim}
\end{frame}

\section{Exercise 4 : Transformations/Actions on DataFrames, Join}
\section{Exercise 5 : Transformations/Actions on DataFrames}
\section{Exercise 6 : Saving JSON file}
\section{Exercise 7 : Machine Learning}


\end{CJK}
\end{document}
